{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import threading\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import face_recognition\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = {}\n",
    "server_sockets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_client(conn, addr, client_name):\n",
    "    \"\"\"\n",
    "    Handles communication with a connected client.\n",
    "    \"\"\"\n",
    "    print(f\"{client_name} connected from {addr}\")\n",
    "    connections[client_name] = conn\n",
    "    try:\n",
    "        while True:\n",
    "            data = conn.recv(1024)  # Receive data\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            message = data[2:].decode('utf-8')\n",
    "\n",
    "            message_dict = json.loads(message)\n",
    "\n",
    "            if client_name == \"Java\":\n",
    "                modelIndex = message_dict.get(\"ModelIndex\", None)\n",
    "\n",
    "                if modelIndex:\n",
    "                    send_structured_message(\"Unity\", \"ChangeModel\", modelIndex)\n",
    "\n",
    "            print(f\"Received from {client_name}: {message_dict}\")\n",
    "    except ConnectionResetError:\n",
    "        print(f\"{client_name} disconnected.\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "        if client_name in connections:\n",
    "            del connections[client_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_server(port, client_name):\n",
    "    \"\"\"\n",
    "    Starts a server socket listening on a specified port for a specific client.\n",
    "    \"\"\"\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind(('127.0.0.1', port))\n",
    "    server_socket.listen(5)\n",
    "    server_sockets.append(server_socket)  # Track the server socket\n",
    "    print(f\"Server listening for {client_name} on port {port}...\")\n",
    "    try:\n",
    "        while True:\n",
    "            conn, addr = server_socket.accept()\n",
    "            threading.Thread(target=handle_client, args=(conn, addr, client_name)).start()\n",
    "    except Exception as e:\n",
    "        print(f\"Server for {client_name} on port {port} encountered an error: {e}\")\n",
    "    finally:\n",
    "        server_socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_to(client_name, message):\n",
    "    \"\"\"\n",
    "    Sends a message to a connected client.\n",
    "    \"\"\"\n",
    "    if client_name in connections:\n",
    "        try:\n",
    "            encodedMessage = message.encode()\n",
    "            connections[client_name].send(encodedMessage)\n",
    "            print(f\"Sending message: {encodedMessage}\")\n",
    "        except BrokenPipeError:\n",
    "            print(f\"Failed to send message to {client_name}. Connection might be closed.\")\n",
    "    else:\n",
    "        print(f\"{client_name} is not connected. {message} can't be sent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_structured_message(client_name, action, value):\n",
    "    obj = {\"Action\": action, \"Value\": value}\n",
    "    jsonData = json.dumps(obj)\n",
    "    send_message_to(client_name, jsonData + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_all_connections():\n",
    "    \"\"\"\n",
    "    Closes all client connections and server sockets.\n",
    "    \"\"\"\n",
    "    print(\"Closing all connections...\")\n",
    "    for client_name, conn in list(connections.items()):\n",
    "        try:\n",
    "            conn.close()\n",
    "            print(f\"Closed connection for {client_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error closing connection for {client_name}: {e}\")\n",
    "        finally:\n",
    "            del connections[client_name]\n",
    "\n",
    "    for server_socket in server_sockets:\n",
    "        try:\n",
    "            server_socket.close()\n",
    "            print(\"Server socket closed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error closing server socket: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_red = np.array([0, 0, 0])\n",
    "upper_red = np.array([0, 95, 10])\n",
    "\n",
    "def detect_led(frame, lower_red, upper_red):\n",
    "    \"\"\"\n",
    "    Detects an LED in the given frame and returns its bounding rectangle\n",
    "    along with the modified frame with a rectangle drawn around the detected LED, if any.\n",
    "    \"\"\"\n",
    "    # Convert the frame to the HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask for the LED light color using the threshold values\n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # Apply morphological operations to remove noise\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Check if any contours were found\n",
    "    if len(contours) > 0:\n",
    "        # Find the largest contour\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Get the bounding rectangle for the contour\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Draw a rectangle around the LED light\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Return the position of the LED as the center of the bounding box\n",
    "        return frame, (x + w // 2, y + h // 2)\n",
    "\n",
    "    return frame, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali_image = face_recognition.load_image_file(\"people/ali.jpg\")\n",
    "ali_face_encoding = face_recognition.face_encodings(ali_image)[0]\n",
    "\n",
    "known_face_encodings = [\n",
    "    ali_face_encoding,\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Ali ElRogbany\",\n",
    "]\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "\n",
    "# Facial Recognition Function\n",
    "def detect_faces(frame, known_face_encodings, known_face_names):\n",
    "    rgb_small_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "    face_locations = []\n",
    "    face_names = []\n",
    "\n",
    "    # Detect faces and their encodings\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # Find the best match for the detected face\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "\n",
    "        face_names.append(name)\n",
    "\n",
    "    return face_locations, face_names, len(face_encodings) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"./shape_predictor_68_face_landmarks.dat\")\n",
    "gaze_data = []\n",
    "\n",
    "def track_gaze(frame):\n",
    "    colored_frame = frame.copy()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shape = predictor(gray, face)\n",
    "\n",
    "        landmarks = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "\n",
    "        left_eye_indices = [36, 37, 38, 39, 40, 41]\n",
    "        right_eye_indices = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "        left_eye = landmarks[left_eye_indices]\n",
    "        right_eye = landmarks[right_eye_indices]\n",
    "\n",
    "        left_eye_center = np.mean(left_eye, axis=0).astype(int)\n",
    "        right_eye_center = np.mean(right_eye, axis=0).astype(int)\n",
    "\n",
    "        avg_x = int((left_eye_center[0] + right_eye_center[0]) / 2)\n",
    "        avg_y = int((left_eye_center[1] + right_eye_center[1]) / 2)\n",
    "\n",
    "        gaze_data.append((avg_x, avg_y))\n",
    "\n",
    "        cv2.circle(colored_frame, tuple(left_eye_center), 3, (0, 255, 0), -1)\n",
    "        cv2.circle(colored_frame, tuple(right_eye_center), 3, (0, 255, 0), -1)\n",
    "        cv2.circle(colored_frame, (avg_x, avg_y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    return colored_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gaze_data_to_csv():\n",
    "    \"\"\"Transform gaze data list to pandas dataframe and save as CSV with a timestamped filename.\"\"\"\n",
    "    if not gaze_data:\n",
    "        print(\"No gaze data to save.\")\n",
    "        return\n",
    "\n",
    "    # Generate a timestamped filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_name = f\"gaze_data_{timestamp}.csv\"\n",
    "\n",
    "    # Save data to CSV\n",
    "    df = pd.DataFrame(gaze_data, columns=['x', 'y'])\n",
    "    df.to_csv(f\"gazedata/{file_name}\", index=False)\n",
    "    print(f\"Gaze data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_servers():\n",
    "    \"\"\"\n",
    "    Starts server threads and keeps them running in a while loop.\n",
    "    \"\"\"\n",
    "    threading.Thread(target=start_server, args=(3000, \"Java\")).start()\n",
    "    threading.Thread(target=start_server, args=(4200, \"Unity\")).start()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    framecnt = 0\n",
    "\n",
    "    last_position = None\n",
    "\n",
    "    face_found = False\n",
    "    frame_has_faces = False\n",
    "\n",
    "    current_user_age = 18\n",
    "    current_user_expression = \"None\"\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Read the frame from the camera\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Failed to read frame from camera.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (0, 0), fx=0.50, fy=0.50)\n",
    "            framecnt += 1\n",
    "\n",
    "            if framecnt % 23 == 0:\n",
    "                # LED Tracking\n",
    "                led_tracked_frame, current_position = detect_led(frame, lower_red, upper_red)\n",
    "\n",
    "                if current_position is not None:\n",
    "                    if last_position is not None:\n",
    "                        # Calculate the position difference\n",
    "                        dx = current_position[0] - last_position[0]\n",
    "                        dy = current_position[1] - last_position[1]\n",
    "                        send_structured_message(\"Unity\", \"RotateModel\", dx)\n",
    "\n",
    "                    # Update the last position\n",
    "                    last_position = current_position\n",
    "\n",
    "                # Facial Recognition\n",
    "                face_locations, face_names, frame_has_faces = detect_faces(frame, known_face_encodings, known_face_names)\n",
    "                new_face_found = len(face_names) > 0\n",
    "                if new_face_found != face_found:\n",
    "                    face_found = new_face_found\n",
    "                    send_structured_message(\"Java\", \"FaceIdentification\", face_found)\n",
    "\n",
    "                # Gaze Tracking\n",
    "                gaze_detection_frame = track_gaze(frame)\n",
    "\n",
    "            if framecnt % 69 == 0 and frame_has_faces:\n",
    "                framecnt = 0\n",
    "\n",
    "                required_outputs =  ['age', 'emotion']\n",
    "                result = DeepFace.analyze(frame, actions = required_outputs, enforce_detection = False)\n",
    "                if len(result) > 0:\n",
    "                    current_user_age = result[0][\"age\"]\n",
    "                    current_user_expression = result[0][\"dominant_emotion\"]\n",
    "\n",
    "            cv2.putText(frame, f\"Expression: {current_user_expression}\", (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "            # Display the frame\n",
    "            cv2.imshow('Python Server', frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down servers...\")\n",
    "    finally:\n",
    "        close_all_connections()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        save_gaze_data_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server listening for Java on port 3000...\n",
      "Server listening for Unity on port 4200...\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": false}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": false}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": false}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": false}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": false}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": false}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": false}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": false}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": false}\n",
      " can't be sent.\n",
      "Java is not connected. {\"Action\": \"FaceIdentification\", \"Value\": true}\n",
      " can't be sent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing all connections...\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server for Java on port 3000 encountered an error: [WinError 10038] An operation was attempted on something that is not a socket\n",
      "Server socket closed.\n",
      "Server for Unity on port 4200 encountered an error: [WinError 10038] An operation was attempted on something that is not a socket\n",
      "Gaze data saved to gaze_data_20241230_102420.csv\n"
     ]
    }
   ],
   "source": [
    "run_servers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
