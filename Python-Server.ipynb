{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import threading\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = {}\n",
    "server_sockets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_client(conn, addr, client_name):\n",
    "    \"\"\"\n",
    "    Handles communication with a connected client.\n",
    "    \"\"\"\n",
    "    print(f\"{client_name} connected from {addr}\")\n",
    "    connections[client_name] = conn\n",
    "    try:\n",
    "        while True:\n",
    "            data = conn.recv(1024)  # Receive data\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            message = data[2:].decode('utf-8')\n",
    "\n",
    "            message_dict = json.loads(message)\n",
    "\n",
    "            if client_name == \"Java\":\n",
    "                modelIndex = message_dict.get(\"ModelIndex\", None)\n",
    "\n",
    "                if modelIndex:\n",
    "                    send_structured_message(\"Unity\", \"ChangeModel\", modelIndex)\n",
    "\n",
    "            print(f\"Received from {client_name}: {message_dict}\")\n",
    "    except ConnectionResetError:\n",
    "        print(f\"{client_name} disconnected.\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "        if client_name in connections:\n",
    "            del connections[client_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_server(port, client_name):\n",
    "    \"\"\"\n",
    "    Starts a server socket listening on a specified port for a specific client.\n",
    "    \"\"\"\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind(('127.0.0.1', port))\n",
    "    server_socket.listen(5)\n",
    "    server_sockets.append(server_socket)  # Track the server socket\n",
    "    print(f\"Server listening for {client_name} on port {port}...\")\n",
    "    try:\n",
    "        while True:\n",
    "            conn, addr = server_socket.accept()\n",
    "            threading.Thread(target=handle_client, args=(conn, addr, client_name)).start()\n",
    "    except Exception as e:\n",
    "        print(f\"Server for {client_name} on port {port} encountered an error: {e}\")\n",
    "    finally:\n",
    "        server_socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_to(client_name, message):\n",
    "    \"\"\"\n",
    "    Sends a message to a connected client.\n",
    "    \"\"\"\n",
    "    if client_name in connections:\n",
    "        try:\n",
    "            encodedMessage = message.encode()\n",
    "            connections[client_name].send(encodedMessage)\n",
    "            print(f\"Sending message: {encodedMessage}\")\n",
    "        except BrokenPipeError:\n",
    "            print(f\"Failed to send message to {client_name}. Connection might be closed.\")\n",
    "    else:\n",
    "        print(f\"{client_name} is not connected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_structured_message(client_name, action, value):\n",
    "    obj = {\"Action\": action, \"Value\": value}\n",
    "    jsonData = json.dumps(obj)\n",
    "    send_message_to(client_name, jsonData + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_all_connections():\n",
    "    \"\"\"\n",
    "    Closes all client connections and server sockets.\n",
    "    \"\"\"\n",
    "    print(\"Closing all connections...\")\n",
    "    for client_name, conn in list(connections.items()):\n",
    "        try:\n",
    "            conn.close()\n",
    "            print(f\"Closed connection for {client_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error closing connection for {client_name}: {e}\")\n",
    "        finally:\n",
    "            del connections[client_name]\n",
    "\n",
    "    for server_socket in server_sockets:\n",
    "        try:\n",
    "            server_socket.close()\n",
    "            print(\"Server socket closed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error closing server socket: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_red = np.array([0, 0, 0])\n",
    "upper_red = np.array([0, 95, 10])\n",
    "\n",
    "def detect_led(frame, lower_red, upper_red):\n",
    "    \"\"\"\n",
    "    Detects an LED in the given frame and returns its bounding rectangle\n",
    "    along with the modified frame with a rectangle drawn around the detected LED, if any.\n",
    "    \"\"\"\n",
    "    # Convert the frame to the HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask for the LED light color using the threshold values\n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # Apply morphological operations to remove noise\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Check if any contours were found\n",
    "    if len(contours) > 0:\n",
    "        # Find the largest contour\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Get the bounding rectangle for the contour\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Draw a rectangle around the LED light\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Return the position of the LED as the center of the bounding box\n",
    "        return frame, (x + w // 2, y + h // 2)\n",
    "\n",
    "    return frame, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali_image = face_recognition.load_image_file(\"people/ali.jpg\")\n",
    "ali_face_encoding = face_recognition.face_encodings(ali_image)[0]\n",
    "\n",
    "known_face_encodings = [\n",
    "    ali_face_encoding,\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Ali ElRogbany\",\n",
    "]\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "\n",
    "# Facial Recognition Function\n",
    "def detect_faces(frame, known_face_encodings, known_face_names):\n",
    "    rgb_small_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "    face_locations = []\n",
    "    face_names = []\n",
    "\n",
    "    # Detect faces and their encodings\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # Find the best match for the detected face\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "\n",
    "        face_names.append(name)\n",
    "\n",
    "    return face_locations, face_names, len(face_encodings) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_servers():\n",
    "    \"\"\"\n",
    "    Starts server threads and keeps them running in a while loop.\n",
    "    \"\"\"\n",
    "    threading.Thread(target=start_server, args=(3000, \"Java\")).start()\n",
    "    threading.Thread(target=start_server, args=(4200, \"Unity\")).start()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    framecnt = 0\n",
    "\n",
    "    last_position = None\n",
    "\n",
    "    face_found = False\n",
    "    frame_has_faces = False\n",
    "\n",
    "    current_user_age = 18\n",
    "    current_user_expression = \"None\"\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Read the frame from the camera\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Failed to read frame from camera.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "            framecnt += 1\n",
    "\n",
    "            if framecnt % 23 == 0:\n",
    "                # LED Tracking\n",
    "                frame, current_position = detect_led(frame, lower_red, upper_red)\n",
    "\n",
    "                if current_position is not None:\n",
    "                    if last_position is not None:\n",
    "                        # Calculate the position difference\n",
    "                        dx = current_position[0] - last_position[0]\n",
    "                        dy = current_position[1] - last_position[1]\n",
    "                        send_structured_message(\"Unity\", \"RotateModel\", dx)\n",
    "\n",
    "                    # Update the last position\n",
    "                    last_position = current_position\n",
    "\n",
    "                # Facial Recognition\n",
    "                face_locations, face_names, frame_has_faces = detect_faces(frame, known_face_encodings, known_face_names)\n",
    "                new_face_found = len(face_names) > 0\n",
    "                if new_face_found != face_found:\n",
    "                    face_found = new_face_found\n",
    "                    send_structured_message(\"Java\", \"FaceIdentification\", face_found)\n",
    "\n",
    "            if framecnt % 69 == 0 and frame_has_faces:\n",
    "                framecnt = 0\n",
    "\n",
    "                required_outputs =  ['age', 'emotion']\n",
    "                result = DeepFace.analyze(frame, actions = required_outputs, enforce_detection = False)\n",
    "                if len(result) > 0:\n",
    "                    current_user_age = result[0][\"age\"]\n",
    "                    current_user_expression = result[0][\"dominant_emotion\"]\n",
    "\n",
    "            cv2.putText(frame, f\"Expression: {current_user_expression}\", (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "            # Display the frame\n",
    "            cv2.imshow('Python Server', frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down servers...\")\n",
    "    finally:\n",
    "        close_all_connections()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server listening for Java on port 3000...\n",
      "Server listening for Unity on port 4200...\n",
      "Java is not connected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.75it/s]\n",
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing all connections...\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server socket closed.\n",
      "Server for Unity on port 4200 encountered an error: [WinError 10038] An operation was attempted on something that is not a socket\n",
      "Server for Java on port 3000 encountered an error: [WinError 10038] An operation was attempted on something that is not a socket\n"
     ]
    }
   ],
   "source": [
    "run_servers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
